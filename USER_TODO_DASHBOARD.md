# USER TODO - Configuration Supabase pour Dashboard Analytics

Ce document liste **toutes les tÃ¢ches que vous devez effectuer dans Supabase** avant que je puisse continuer le dÃ©veloppement du dashboard. Je ne peux pas effectuer ces modifications de maniÃ¨re sÃ»re car elles touchent directement Ã  la structure de votre base de donnÃ©es en production.

---

## ğŸ“‹ Vue d'ensemble

**Pourquoi ces tÃ¢ches manuelles ?**
- Modifications de schÃ©ma database (crÃ©ation tables, colonnes, indexes)
- Configuration de sÃ©curitÃ© critique (RLS policies)
- Optimisations performance (BRIN indexes, materialized views)
- Risque de perte de donnÃ©es si mal exÃ©cutÃ©es

**Mon rÃ´le (Claude Code)** :
- âœ… GÃ©nÃ©rer tout le code SQL nÃ©cessaire (voir ci-dessous)
- âœ… CrÃ©er les composants React/Next.js
- âœ… Configurer TanStack Query et routing
- âœ… ImplÃ©menter les visualisations et filtres

**Votre rÃ´le** :
- âš ï¸ ExÃ©cuter les scripts SQL dans Supabase
- âš ï¸ VÃ©rifier que tout fonctionne
- âš ï¸ Me confirmer quand c'est fait

---

## ğŸ¯ Checklist des TÃ¢ches

### Phase 1 : PrÃ©paration (5 min)

- [ ] **Backup de la base de donnÃ©es**
  - Aller dans Supabase Dashboard â†’ Database â†’ Backups
  - CrÃ©er un backup manuel avant toute modification
  - TÃ©lÃ©charger un export SQL complet (sÃ©curitÃ©)

- [ ] **Ouvrir SQL Editor**
  - Aller dans Supabase Dashboard â†’ SQL Editor
  - CrÃ©er une nouvelle query nommÃ©e "Dashboard Setup"

---

### Phase 2 : CrÃ©ation des Tables (10 min)

#### âœ… TÃ¢che 1 : CrÃ©er la table `agents`

**Objectif** : GÃ©rer les agents vocaux individuels par client

**SQL Ã  exÃ©cuter** :
```sql
-- Table agents
CREATE TABLE IF NOT EXISTS agents (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  client_id UUID REFERENCES clients(id) ON DELETE CASCADE NOT NULL,
  name TEXT NOT NULL,
  type TEXT CHECK (type IN ('inbound', 'outbound')),
  status TEXT DEFAULT 'active' CHECK (status IN ('active', 'inactive', 'archived')),
  metadata JSONB DEFAULT '{}'::jsonb,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Index pour performance
CREATE INDEX IF NOT EXISTS idx_agents_client_id ON agents(client_id);
CREATE INDEX IF NOT EXISTS idx_agents_status ON agents(status) WHERE status = 'active';

-- Trigger pour updated_at
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_agents_updated_at
  BEFORE UPDATE ON agents
  FOR EACH ROW
  EXECUTE FUNCTION update_updated_at_column();

-- Enable RLS
ALTER TABLE agents ENABLE ROW LEVEL SECURITY;

-- Policy : Users voient les agents de leurs clients
CREATE POLICY "users_view_their_agents"
  ON agents FOR SELECT
  TO authenticated
  USING (
    client_id IN (
      SELECT client_id FROM user_client_permissions
      WHERE user_id = auth.uid()
    )
  );

COMMENT ON TABLE agents IS 'Agents vocaux IA appartenant aux clients';
```

**VÃ©rification** :
```sql
-- Doit retourner la structure de la table agents
SELECT * FROM agents LIMIT 1;
```

- [ ] **ConfirmÃ© : Table `agents` crÃ©Ã©e avec succÃ¨s**

---

#### âœ… TÃ¢che 2 : CrÃ©er la table `user_client_permissions`

**Objectif** : GÃ©rer qui peut voir quels clients (permissions granulaires)

**SQL Ã  exÃ©cuter** :
```sql
-- Table permissions
CREATE TABLE IF NOT EXISTS user_client_permissions (
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE NOT NULL,
  client_id UUID REFERENCES clients(id) ON DELETE CASCADE NOT NULL,
  permission_level TEXT NOT NULL DEFAULT 'read' CHECK (permission_level IN ('read', 'write', 'admin')),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  PRIMARY KEY (user_id, client_id)
);

-- Index
CREATE INDEX IF NOT EXISTS idx_user_client_permissions_user ON user_client_permissions(user_id);
CREATE INDEX IF NOT EXISTS idx_user_client_permissions_client ON user_client_permissions(client_id);

-- Enable RLS
ALTER TABLE user_client_permissions ENABLE ROW LEVEL SECURITY;

-- Policy : Users voient leurs propres permissions
CREATE POLICY "users_view_own_permissions"
  ON user_client_permissions FOR SELECT
  TO authenticated
  USING (user_id = auth.uid());

COMMENT ON TABLE user_client_permissions IS 'Permissions granulaires user-client';
```

**VÃ©rification** :
```sql
-- Doit retourner la structure de la table
SELECT * FROM user_client_permissions LIMIT 1;
```

- [ ] **ConfirmÃ© : Table `user_client_permissions` crÃ©Ã©e avec succÃ¨s**

---

### Phase 3 : Modification de la Table `calls` (5 min)

#### âœ… TÃ¢che 3 : Ajouter la colonne `agent_id`

**Objectif** : Lier chaque appel Ã  un agent spÃ©cifique

**SQL Ã  exÃ©cuter** :
```sql
-- Ajouter colonne agent_id si elle n'existe pas
ALTER TABLE calls
ADD COLUMN IF NOT EXISTS agent_id UUID REFERENCES agents(id) ON DELETE SET NULL;

-- Ajouter index pour performance
CREATE INDEX IF NOT EXISTS idx_calls_agent_id ON calls(agent_id);

COMMENT ON COLUMN calls.agent_id IS 'Agent vocal ayant passÃ© cet appel';
```

**VÃ©rification** :
```sql
-- Doit afficher la colonne agent_id
SELECT column_name, data_type, is_nullable
FROM information_schema.columns
WHERE table_name = 'calls' AND column_name = 'agent_id';
```

- [ ] **ConfirmÃ© : Colonne `agent_id` ajoutÃ©e Ã  `calls`**

---

### Phase 4 : Indexes de Performance (10 min)

#### âœ… TÃ¢che 4 : CrÃ©er les indexes critiques

**Objectif** : Optimiser les requÃªtes time-series et filtres frÃ©quents

**SQL Ã  exÃ©cuter** :
```sql
-- BRIN index pour started_at (99% plus lÃ©ger que B-tree pour time-series)
CREATE INDEX IF NOT EXISTS idx_calls_started_at_brin
ON calls USING BRIN (started_at)
WITH (pages_per_range = 128);

-- Composite indexes pour filtres frÃ©quents
CREATE INDEX IF NOT EXISTS idx_calls_client_started
ON calls (client_id, started_at DESC);

CREATE INDEX IF NOT EXISTS idx_calls_agent_started
ON calls (agent_id, started_at DESC);

CREATE INDEX IF NOT EXISTS idx_calls_client_agent_started
ON calls (client_id, agent_id, started_at DESC);

-- Index pour filtrage par call_outcome
CREATE INDEX IF NOT EXISTS idx_calls_outcome
ON calls (call_outcome) WHERE call_outcome IS NOT NULL;

-- Index pour filtrage par Ã©motion
CREATE INDEX IF NOT EXISTS idx_calls_emotion
ON calls (emotion) WHERE emotion IS NOT NULL;

-- Index pour les RDV
CREATE INDEX IF NOT EXISTS idx_calls_appointments
ON calls (appointment_scheduled_at) WHERE appointment_scheduled_at IS NOT NULL;
```

**VÃ©rification** :
```sql
-- Doit afficher tous les indexes crÃ©Ã©s
SELECT indexname, indexdef
FROM pg_indexes
WHERE tablename = 'calls'
ORDER BY indexname;
```

- [ ] **ConfirmÃ© : Tous les indexes crÃ©Ã©s avec succÃ¨s**

---

### Phase 5 : Materialized View (15 min)

#### âœ… TÃ¢che 5 : CrÃ©er la vue matÃ©rialisÃ©e pour mÃ©triques quotidiennes

**Objectif** : PrÃ©-calculer les agrÃ©gations pour amÃ©liorer les performances

**SQL Ã  exÃ©cuter** :
```sql
-- Vue matÃ©rialisÃ©e pour mÃ©triques quotidiennes
CREATE MATERIALIZED VIEW IF NOT EXISTS daily_call_metrics AS
SELECT
  client_id,
  agent_id,
  DATE(started_at) as metric_date,

  -- MÃ©triques prioritaires
  COUNT(*) FILTER (WHERE appointment_scheduled_at IS NOT NULL) as appointments_scheduled,
  COUNT(*) FILTER (WHERE call_outcome = 'voicemail') as voicemail_count,
  COUNT(*) FILTER (WHERE call_outcome IN ('appointment_scheduled', 'appointment_refused', 'not_interested', 'callback_requested')) as answered_count,

  -- DurÃ©e et coÃ»t
  ROUND(AVG(duration_seconds)) as avg_duration_seconds,
  ROUND(SUM(cost)::NUMERIC, 2) as total_cost,
  ROUND(AVG(cost)::NUMERIC, 2) as avg_cost,

  -- Distribution Ã©motions
  COUNT(*) FILTER (WHERE emotion = 'positive') as emotion_positive,
  COUNT(*) FILTER (WHERE emotion = 'neutral') as emotion_neutral,
  COUNT(*) FILTER (WHERE emotion = 'negative') as emotion_negative,

  -- Total
  COUNT(*) as total_calls

FROM calls
WHERE started_at >= CURRENT_DATE - INTERVAL '365 days'
GROUP BY client_id, agent_id, DATE(started_at);

-- Index sur la vue matÃ©rialisÃ©e
CREATE UNIQUE INDEX IF NOT EXISTS idx_daily_metrics_unique
ON daily_call_metrics (client_id, agent_id, metric_date);

CREATE INDEX IF NOT EXISTS idx_daily_metrics_client_date
ON daily_call_metrics (client_id, metric_date DESC);

CREATE INDEX IF NOT EXISTS idx_daily_metrics_agent_date
ON daily_call_metrics (agent_id, metric_date DESC);

COMMENT ON MATERIALIZED VIEW daily_call_metrics IS 'AgrÃ©gations quotidiennes des mÃ©triques d appels (refresh horaire recommandÃ©)';
```

**Premier refresh** :
```sql
REFRESH MATERIALIZED VIEW CONCURRENTLY daily_call_metrics;
```

**VÃ©rification** :
```sql
-- Doit afficher des donnÃ©es agrÃ©gÃ©es
SELECT * FROM daily_call_metrics LIMIT 10;

-- VÃ©rifier le nombre de rows
SELECT COUNT(*) FROM daily_call_metrics;
```

- [ ] **ConfirmÃ© : Materialized view crÃ©Ã©e et populÃ©e**

---

#### âœ… TÃ¢che 5b : Configurer le refresh automatique (OPTIONNEL)

**Option A - Via pg_cron (si disponible)** :
```sql
-- VÃ©rifier si pg_cron est disponible
SELECT * FROM pg_extension WHERE extname = 'pg_cron';

-- Si disponible, crÃ©er un job pour refresh toutes les heures
SELECT cron.schedule(
  'refresh-daily-metrics',
  '0 * * * *', -- Toutes les heures
  $$REFRESH MATERIALIZED VIEW CONCURRENTLY daily_call_metrics$$
);
```

**Option B - Refresh manuel rÃ©gulier** :
- CrÃ©er un reminder pour exÃ©cuter le refresh 1x/jour :
```sql
REFRESH MATERIALIZED VIEW CONCURRENTLY daily_call_metrics;
```

**Option C - Via l'application Next.js** :
- Je peux crÃ©er un API route qui refresh la view (Ã  appeler via cron externe)

- [ ] **ConfirmÃ© : Refresh automatique configurÃ©** (ou dÃ©cision prise)

---

### Phase 6 : Fonctions SQL pour Queries Complexes (10 min)

#### âœ… TÃ¢che 6 : CrÃ©er la fonction `get_kpi_metrics`

**Objectif** : Fonction optimisÃ©e pour calculer les KPIs

**SQL Ã  exÃ©cuter** :
```sql
-- Fonction pour obtenir les KPIs avec pÃ©riode de comparaison
CREATE OR REPLACE FUNCTION get_kpi_metrics(
  p_start_date TIMESTAMPTZ,
  p_end_date TIMESTAMPTZ,
  p_client_id UUID DEFAULT NULL,
  p_agent_id UUID DEFAULT NULL
)
RETURNS JSON
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  result JSON;
  prev_start_date TIMESTAMPTZ;
  prev_end_date TIMESTAMPTZ;
BEGIN
  -- Calculer pÃ©riode prÃ©cÃ©dente de mÃªme durÃ©e
  prev_end_date := p_start_date - INTERVAL '1 second';
  prev_start_date := prev_end_date - (p_end_date - p_start_date);

  -- Construire le JSON de rÃ©sultats
  SELECT json_build_object(
    'current_period', (
      SELECT json_build_object(
        'appointments_scheduled', COUNT(*) FILTER (WHERE appointment_scheduled_at IS NOT NULL),
        'answer_rate', COALESCE(ROUND((COUNT(*) FILTER (WHERE call_outcome IN ('appointment_scheduled', 'appointment_refused', 'not_interested', 'callback_requested'))::NUMERIC / NULLIF(COUNT(*), 0) * 100), 2), 0),
        'avg_duration', COALESCE(ROUND(AVG(duration_seconds)), 0),
        'avg_cost', COALESCE(ROUND(AVG(cost)::NUMERIC, 2), 0),
        'conversion_rate', COALESCE(ROUND((COUNT(*) FILTER (WHERE appointment_scheduled_at IS NOT NULL)::NUMERIC / NULLIF(COUNT(*) FILTER (WHERE call_outcome IN ('appointment_scheduled', 'appointment_refused', 'not_interested', 'callback_requested')), 0) * 100), 2), 0),
        'total_cost', COALESCE(ROUND(SUM(cost)::NUMERIC, 2), 0),
        'total_calls', COUNT(*),
        'cpa', COALESCE(ROUND((SUM(cost) / NULLIF(COUNT(*) FILTER (WHERE appointment_scheduled_at IS NOT NULL), 0))::NUMERIC, 2), 0)
      )
      FROM calls
      WHERE started_at >= p_start_date
        AND started_at <= p_end_date
        AND (p_client_id IS NULL OR client_id = p_client_id)
        AND (p_agent_id IS NULL OR agent_id = p_agent_id)
    ),
    'previous_period', (
      SELECT json_build_object(
        'appointments_scheduled', COUNT(*) FILTER (WHERE appointment_scheduled_at IS NOT NULL),
        'answer_rate', COALESCE(ROUND((COUNT(*) FILTER (WHERE call_outcome IN ('appointment_scheduled', 'appointment_refused', 'not_interested', 'callback_requested'))::NUMERIC / NULLIF(COUNT(*), 0) * 100), 2), 0),
        'avg_duration', COALESCE(ROUND(AVG(duration_seconds)), 0),
        'avg_cost', COALESCE(ROUND(AVG(cost)::NUMERIC, 2), 0),
        'conversion_rate', COALESCE(ROUND((COUNT(*) FILTER (WHERE appointment_scheduled_at IS NOT NULL)::NUMERIC / NULLIF(COUNT(*) FILTER (WHERE call_outcome IN ('appointment_scheduled', 'appointment_refused', 'not_interested', 'callback_requested')), 0) * 100), 2), 0),
        'total_calls', COUNT(*)
      )
      FROM calls
      WHERE started_at >= prev_start_date
        AND started_at <= prev_end_date
        AND (p_client_id IS NULL OR client_id = p_client_id)
        AND (p_agent_id IS NULL OR agent_id = p_agent_id)
    )
  )
  INTO result;

  RETURN result;
END;
$$;

COMMENT ON FUNCTION get_kpi_metrics IS 'Calcule les KPIs pour une pÃ©riode avec comparaison pÃ©riode prÃ©cÃ©dente';
```

**VÃ©rification** :
```sql
-- Test de la fonction (adapter les dates)
SELECT get_kpi_metrics(
  '2024-01-01'::TIMESTAMPTZ,
  NOW()::TIMESTAMPTZ,
  NULL, -- Tous les clients
  NULL  -- Tous les agents
);
```

- [ ] **ConfirmÃ© : Fonction `get_kpi_metrics` crÃ©Ã©e et testÃ©e**

---

#### âœ… TÃ¢che 7 : CrÃ©er la fonction `get_chart_data`

**Objectif** : Fonction pour obtenir les donnÃ©es de charts

**SQL Ã  exÃ©cuter** :
```sql
-- Fonction pour obtenir les donnÃ©es des charts
CREATE OR REPLACE FUNCTION get_chart_data(
  p_start_date TIMESTAMPTZ,
  p_end_date TIMESTAMPTZ,
  p_client_id UUID DEFAULT NULL,
  p_agent_id UUID DEFAULT NULL
)
RETURNS JSON
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  result JSON;
BEGIN
  SELECT json_build_object(
    'call_volume_by_day', (
      SELECT json_agg(
        json_build_object(
          'date', TO_CHAR(DATE(started_at), 'YYYY-MM-DD'),
          'total_calls', COUNT(*),
          'answered_calls', COUNT(*) FILTER (WHERE call_outcome IN ('appointment_scheduled', 'appointment_refused', 'not_interested', 'callback_requested')),
          'appointments', COUNT(*) FILTER (WHERE appointment_scheduled_at IS NOT NULL)
        ) ORDER BY DATE(started_at)
      )
      FROM calls
      WHERE started_at >= p_start_date
        AND started_at <= p_end_date
        AND (p_client_id IS NULL OR client_id = p_client_id)
        AND (p_agent_id IS NULL OR agent_id = p_agent_id)
      GROUP BY DATE(started_at)
    ),
    'emotion_distribution', (
      SELECT json_agg(
        json_build_object(
          'emotion', COALESCE(emotion, 'unknown'),
          'count', COUNT(*)
        )
      )
      FROM calls
      WHERE started_at >= p_start_date
        AND started_at <= p_end_date
        AND (p_client_id IS NULL OR client_id = p_client_id)
        AND (p_agent_id IS NULL OR agent_id = p_agent_id)
      GROUP BY emotion
    ),
    'outcome_distribution', (
      SELECT json_agg(
        json_build_object(
          'outcome', call_outcome::TEXT,
          'count', COUNT(*)
        ) ORDER BY COUNT(*) DESC
      )
      FROM calls
      WHERE started_at >= p_start_date
        AND started_at <= p_end_date
        AND (p_client_id IS NULL OR client_id = p_client_id)
        AND (p_agent_id IS NULL OR agent_id = p_agent_id)
        AND call_outcome IS NOT NULL
      GROUP BY call_outcome
    ),
    'voicemail_by_agent', (
      SELECT json_agg(
        json_build_object(
          'agent', COALESCE(a.name, 'Unknown'),
          'rate', ROUND((COUNT(*) FILTER (WHERE c.call_outcome = 'voicemail')::NUMERIC / NULLIF(COUNT(*), 0) * 100), 2)
        ) ORDER BY ROUND((COUNT(*) FILTER (WHERE c.call_outcome = 'voicemail')::NUMERIC / NULLIF(COUNT(*), 0) * 100), 2) DESC
      )
      FROM calls c
      LEFT JOIN agents a ON c.agent_id = a.id
      WHERE c.started_at >= p_start_date
        AND c.started_at <= p_end_date
        AND (p_client_id IS NULL OR c.client_id = p_client_id)
        AND (p_agent_id IS NULL OR c.agent_id = p_agent_id)
      GROUP BY a.name
    )
  )
  INTO result;

  RETURN result;
END;
$$;

COMMENT ON FUNCTION get_chart_data IS 'Retourne les donnÃ©es pour tous les charts du dashboard';
```

**VÃ©rification** :
```sql
-- Test de la fonction
SELECT get_chart_data(
  '2024-01-01'::TIMESTAMPTZ,
  NOW()::TIMESTAMPTZ,
  NULL,
  NULL
);
```

- [ ] **ConfirmÃ© : Fonction `get_chart_data` crÃ©Ã©e et testÃ©e**

---

### Phase 7 : RLS Policies (15 min)

#### âœ… TÃ¢che 8 : Configurer les RLS policies sur `calls`

**Objectif** : SÃ©curiser l'accÃ¨s aux donnÃ©es (isolation client)

**SQL Ã  exÃ©cuter** :
```sql
-- S'assurer que RLS est activÃ©
ALTER TABLE calls ENABLE ROW LEVEL SECURITY;

-- Supprimer les anciennes policies si elles existent
DROP POLICY IF EXISTS "users_view_their_calls" ON calls;

-- Policy : Users voient les appels de leurs clients assignÃ©s
CREATE POLICY "users_view_their_calls"
  ON calls FOR SELECT
  TO authenticated
  USING (
    client_id IN (
      SELECT client_id
      FROM user_client_permissions
      WHERE user_id = auth.uid()
    )
  );

-- Policy pour insertion (si nÃ©cessaire dans le futur)
CREATE POLICY "users_insert_to_their_clients"
  ON calls FOR INSERT
  TO authenticated
  WITH CHECK (
    client_id IN (
      SELECT client_id
      FROM user_client_permissions
      WHERE user_id = auth.uid()
      AND permission_level IN ('write', 'admin')
    )
  );
```

**VÃ©rification** :
```sql
-- Afficher toutes les policies sur calls
SELECT schemaname, tablename, policyname, permissive, roles, cmd, qual
FROM pg_policies
WHERE tablename = 'calls';
```

- [ ] **ConfirmÃ© : RLS policies configurÃ©es sur `calls`**

---

#### âœ… TÃ¢che 9 : Configurer les RLS policies sur `clients`

**SQL Ã  exÃ©cuter** :
```sql
-- S'assurer que RLS est activÃ©
ALTER TABLE clients ENABLE ROW LEVEL SECURITY;

-- Policy : Users voient leurs clients assignÃ©s
DROP POLICY IF EXISTS "users_view_their_clients" ON clients;
CREATE POLICY "users_view_their_clients"
  ON clients FOR SELECT
  TO authenticated
  USING (
    id IN (
      SELECT client_id
      FROM user_client_permissions
      WHERE user_id = auth.uid()
    )
  );
```

- [ ] **ConfirmÃ© : RLS policies configurÃ©es sur `clients`**

---

### Phase 8 : DonnÃ©es de Test (OPTIONNEL - 10 min)

#### âœ… TÃ¢che 10 : CrÃ©er des donnÃ©es de test

**Objectif** : Avoir des donnÃ©es pour tester le dashboard

**SQL Ã  exÃ©cuter** :
```sql
-- CrÃ©er un agent de test pour chaque client existant
INSERT INTO agents (client_id, name, type, status)
SELECT
  id,
  name || ' - Agent 1',
  'inbound',
  'active'
FROM clients
ON CONFLICT DO NOTHING;

-- Mettre Ã  jour quelques appels avec des agent_id
WITH agent_mapping AS (
  SELECT
    c.id as client_id,
    a.id as agent_id
  FROM clients c
  LEFT JOIN agents a ON a.client_id = c.id
  WHERE a.type = 'inbound'
  LIMIT 1
)
UPDATE calls
SET agent_id = (SELECT agent_id FROM agent_mapping WHERE agent_mapping.client_id = calls.client_id)
WHERE agent_id IS NULL
  AND client_id IN (SELECT client_id FROM agent_mapping);

-- Refresh la materialized view avec les nouvelles donnÃ©es
REFRESH MATERIALIZED VIEW CONCURRENTLY daily_call_metrics;
```

**VÃ©rification** :
```sql
-- VÃ©rifier qu'on a des agents
SELECT c.name as client_name, a.name as agent_name, a.type, a.status
FROM agents a
JOIN clients c ON a.client_id = c.id;

-- VÃ©rifier qu'on a des appels avec agents
SELECT COUNT(*), agent_id
FROM calls
GROUP BY agent_id;
```

- [ ] **ConfirmÃ© : DonnÃ©es de test crÃ©Ã©es** (ou dÃ©cision de ne pas en crÃ©er)

---

### Phase 9 : Configuration Auth (20-30 min)

#### âœ… TÃ¢che 11 : CrÃ©er un utilisateur de test

**Objectif** : Avoir un user pour tester l'authentification

**Via Supabase Dashboard** :
1. Aller dans Authentication â†’ Users
2. Cliquer sur "Add user"
3. CrÃ©er un utilisateur :
   - Email : `test@voipia.com` (ou votre email)
   - Password : GÃ©nÃ©rer un mot de passe fort
   - Auto Confirm : âœ… Oui
4. Copier le `user_id` (UUID)

**Puis dans SQL Editor** :
```sql
-- Assigner des permissions Ã  cet utilisateur
-- Remplacer 'USER_ID_ICI' par le vrai UUID de l'utilisateur

-- Donner accÃ¨s Ã  tous les clients (pour test)
INSERT INTO user_client_permissions (user_id, client_id, permission_level)
SELECT
  'USER_ID_ICI'::UUID,
  id,
  'admin'
FROM clients
ON CONFLICT DO NOTHING;
```

**VÃ©rification** :
```sql
-- VÃ©rifier les permissions
SELECT
  u.email,
  c.name as client_name,
  ucp.permission_level
FROM user_client_permissions ucp
JOIN auth.users u ON ucp.user_id = u.id
JOIN clients c ON ucp.client_id = c.id;
```

- [ ] **ConfirmÃ© : Utilisateur de test crÃ©Ã© avec permissions**

---

### Phase 10 : Variables d'Environnement (5 min)

#### âœ… TÃ¢che 12 : RÃ©cupÃ©rer les credentials Supabase

**Via Supabase Dashboard** :
1. Aller dans Settings â†’ API
2. Copier :
   - **Project URL** : `https://xxxxx.supabase.co`
   - **anon public key** : `eyJhbGc...` (longue clÃ©)

**CrÃ©er/Mettre Ã  jour `.env.local`** dans votre projet :
```env
NEXT_PUBLIC_SUPABASE_URL=https://xxxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGc...
```

- [ ] **ConfirmÃ© : Fichier `.env.local` crÃ©Ã©/mis Ã  jour**

---

## âœ… Validation Finale

### Checklist de validation

- [ ] âœ… Toutes les tables crÃ©Ã©es (`agents`, `user_client_permissions`)
- [ ] âœ… Colonne `agent_id` ajoutÃ©e Ã  `calls`
- [ ] âœ… Tous les indexes crÃ©Ã©s (BRIN + composites)
- [ ] âœ… Materialized view `daily_call_metrics` crÃ©Ã©e et populÃ©e
- [ ] âœ… Fonctions SQL crÃ©Ã©es (`get_kpi_metrics`, `get_chart_data`)
- [ ] âœ… RLS policies configurÃ©es sur toutes les tables
- [ ] âœ… Utilisateur de test crÃ©Ã© avec permissions
- [ ] âœ… Variables d'environnement configurÃ©es
- [ ] âœ… Backup de la base effectuÃ©

### Tests Ã  effectuer

**Test 1 - Tables et donnÃ©es** :
```sql
-- Doit retourner des rÃ©sultats
SELECT COUNT(*) FROM agents;
SELECT COUNT(*) FROM calls WHERE agent_id IS NOT NULL;
SELECT COUNT(*) FROM daily_call_metrics;
```

**Test 2 - Fonctions** :
```sql
-- Doit retourner du JSON avec des KPIs
SELECT get_kpi_metrics(
  (NOW() - INTERVAL '30 days')::TIMESTAMPTZ,
  NOW()::TIMESTAMPTZ,
  NULL,
  NULL
);

-- Doit retourner du JSON avec des donnÃ©es de charts
SELECT get_chart_data(
  (NOW() - INTERVAL '30 days')::TIMESTAMPTZ,
  NOW()::TIMESTAMPTZ,
  NULL,
  NULL
);
```

**Test 3 - RLS** :
```sql
-- En tant qu'utilisateur connectÃ©, doit voir seulement les clients autorisÃ©s
-- (NÃ©cessite d'Ãªtre connectÃ© via l'app pour vraiment tester)
SELECT * FROM calls LIMIT 10;
```

---

## ğŸš€ Prochaines Ã‰tapes

### Une fois TOUTES les tÃ¢ches cochÃ©es :

1. **Me confirmer** :
   - "J'ai terminÃ© toutes les tÃ¢ches SQL"
   - Partager un screenshot ou copier/coller des rÃ©sultats de validation

2. **Je vais dÃ©velopper** :
   - Installation des dÃ©pendances npm
   - CrÃ©ation de la structure de composants
   - Configuration TanStack Query
   - ImplÃ©mentation du layout dashboard
   - CrÃ©ation des filtres
   - CrÃ©ation des KPI cards
   - CrÃ©ation des charts
   - Mise en place de l'authentification cÃ´tÃ© Next.js

3. **Tests ensemble** :
   - VÃ©rifier que l'authentification fonctionne
   - VÃ©rifier que les donnÃ©es s'affichent correctement
   - VÃ©rifier que les filtres fonctionnent
   - VÃ©rifier que le RLS est respectÃ©

---

## ğŸ“ Support

### Si vous rencontrez un problÃ¨me

**ProblÃ¨me : Une query SQL Ã©choue**
- Lire le message d'erreur complet
- Me le partager avec le contexte (quelle tÃ¢che)
- Je vous fournirai une version corrigÃ©e

**ProblÃ¨me : RLS trop restrictif (aucune donnÃ©e visible)**
- Temporairement dÃ©sactiver RLS pour tester :
```sql
ALTER TABLE calls DISABLE ROW LEVEL SECURITY;
```
- Puis rÃ©activer et ajuster les policies

**ProblÃ¨me : Performance lente**
- VÃ©rifier que tous les indexes sont crÃ©Ã©s
- ExÃ©cuter `ANALYZE calls;` pour mettre Ã  jour les statistiques
- Refresh la materialized view

---

## ğŸ“ Notes Importantes

### Attention aux donnÃ©es sensibles
- âš ï¸ Ne JAMAIS partager votre `SUPABASE_SERVICE_ROLE_KEY` (seulement anon key)
- âš ï¸ Tester les RLS policies avant de dÃ©ployer en production
- âš ï¸ Faire un backup avant toute modification majeure

### Migration future
- Tous les scripts SQL ci-dessus peuvent Ãªtre sauvegardÃ©s en tant que migration
- CrÃ©er un fichier `supabase/migrations/20250115_dashboard_setup.sql`
- Permet de reproduire l'installation sur un autre environnement

### Monitoring
- Surveiller les performances des queries dans Supabase Dashboard â†’ Database â†’ Query Performance
- Les BRIN indexes sont optimaux pour vos donnÃ©es time-series
- La materialized view doit Ãªtre refresh rÃ©guliÃ¨rement

---

**Version** : 1.0
**Date** : 2025-01-15
**Auteur** : Claude Code

**Temps estimÃ© total : 1h30 - 2h00**

---

## ğŸ‰ FÃ©licitations !

Une fois toutes ces tÃ¢ches complÃ©tÃ©es, vous aurez :
- âœ… Une base de donnÃ©es optimisÃ©e pour analytics
- âœ… Des queries ultra-rapides grÃ¢ce aux indexes
- âœ… Une sÃ©curitÃ© robuste avec RLS
- âœ… Des fonctions SQL rÃ©utilisables
- âœ… Une architecture prÃªte pour le dashboard

**Je suis prÃªt Ã  dÃ©velopper dÃ¨s que vous aurez terminÃ© !** ğŸš€
