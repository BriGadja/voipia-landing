# Analyse du Payload end-of-call-report

## Vue d'ensemble

Ce payload contient une mine de donn√©es pour analyser les performances et la qualit√© des appels de vos agents IA. Voici une analyse d√©taill√©e des donn√©es disponibles et leurs utilisations potentielles.

---

## 1. üìä Donn√©es de Latence (D√©j√† identifi√©es)

### A. Latences agr√©g√©es (`stats.latencies`)

**Actuellement disponibles** :
```json
"latencies": {
  "llmLatencies": { "min": 555, "max": 1110, "average": 725, "count": 4 },
  "ttsLatencies": { "min": 207, "max": 207, "average": 207, "count": 1 },
  "totalLatencies": { "min": 555, "max": 1110, "average": 777, "count": 4 }
}
```

**Utilisation** :
- Suivre la performance moyenne/min/max des LLM et TTS
- Identifier les pics de latence
- Optimiser les temps de r√©ponse

### B. Latences d√©taill√©es par message

**Dans chaque message de `conversation.messages`** :
```json
"llmStats": {
  "firstReadableChunkLatency": 488,  // Temps avant le 1er chunk lisible
  "latency": 607                      // Latence totale LLM
},
"ttsStats": {
  "completeLatency": 2092,            // Latence totale TTS
  "firstChunkLatency": 377            // Temps avant le 1er chunk audio
},
"latencyBetweenLlmAndStartSpeaking": 207  // D√©lai LLM ‚Üí d√©but TTS
```

**Utilisation potentielle** :
- Analyser les latences tour par tour (quel turn a le plus de latence ?)
- D√©tecter les variations de performance durant l'appel
- Identifier si certaines phases de la conversation sont plus lentes

---

## 2. üéØ Donn√©es d'Analyse de Conversation (Tr√®s utiles !)

### `postConversationAnalysis` (lignes 202-212)

```json
{
  "sentiment": "neutral",                    // positive, negative, neutral
  "sentimentExplanation": "...",            // Explication du sentiment
  "summary": "...",                         // R√©sum√© de la conversation
  "tags": ["noProfilChangeAsked"],          // Tags automatiques
  "isVoiceMail": true,                      // D√©tection messagerie
  "extractedData": {
    "callClassification": "voicemail"       // Classification de l'appel
  }
}
```

**‚úÖ TR√àS UTILE pour :**
- **Analyse qualitative** : Comprendre le sentiment global des appels
- **Segmentation** : Filtrer les appels par sentiment (positif/n√©gatif/neutre)
- **D√©tection de probl√®mes** : Identifier rapidement les appels probl√©matiques
- **Am√©lioration continue** : Comprendre ce qui g√©n√®re de la frustration
- **KPI qualit√©** : Taux de satisfaction estim√©

**Pourrait enrichir votre table `agent_calls`** :
- Ajouter colonne `sentiment` (ENUM: 'positive', 'negative', 'neutral')
- Ajouter colonne `sentiment_explanation` (TEXT)
- Ajouter colonne `conversation_summary` (TEXT)

---

## 3. üìû LogHistory - Timeline compl√®te de l'appel

### `conversation.logHistory` (lignes 218-312)

Timeline pr√©cise de tous les √©v√©nements :
```json
[
  {"type": "sessionStarted", "timestamp": 1763625406686},
  {"type": "userSpeechStart", "timestamp": 1763625407512},
  {"type": "userSpeechEnd", "timestamp": 1763625408231},
  {"type": "sttTranscription", "timestamp": 1763625408727},
  {"type": "llmComplete", "timestamp": 1763625409335, "turnIndex": 4},
  {"type": "ttsComplete", "timestamp": 1763625411438, "turnIndex": 4},
  {"type": "modelSpeechStart", "timestamp": 1763625419769},
  {"type": "modelSpeechEnd", "timestamp": 1763625430477},
  {"type": "hungUp", "timestamp": 1763625430478}
]
```

**‚úÖ TR√àS UTILE pour :**
- **Calcul de m√©triques avanc√©es** :
  - Temps entre userSpeechEnd et llmComplete (latence de traitement)
  - Temps entre llmComplete et ttsComplete (g√©n√©ration audio)
  - Temps entre ttsComplete et modelSpeechStart (buffering)
  - Dur√©e totale de parole de l'agent vs utilisateur
- **D√©tection de silences** : Combien de temps entre userSpeechEnd et modelSpeechStart ?
- **Analyse d'interruptions** : userSpeechStart pendant modelSpeech = interruption
- **Fluidit√© de la conversation** : Temps de r√©ponse moyen

**Possibilit√©s d'analyse** :
- Moyenne du temps de r√©ponse (userSpeechEnd ‚Üí llmComplete)
- Distribution des pauses/silences
- Taux d'interruption (utilisateur coupe l'agent)
- Identification des "dead air" (silences trop longs)

---

## 4. üí∞ Statistiques de Co√ªts d√©taill√©es

### Actuellement vous utilisez :
- Prix STT/TTS/LLM par appel
- Co√ªt total de session

### Donn√©es suppl√©mentaires disponibles :

**A. D√©tails par composant** :
```json
"sttStats": {
  "durationSeconds": 24.86,
  "price": 0.00083
},
"llmStats": {
  "textInputTokens": 65870,
  "textOutputTokens": 227,
  "textInputPrice": 0.01975,
  "textOutputPrice": 0.00058,
  "totalPrice": 0.02033,
  "generationsCount": 5           // ‚Üê Nombre d'appels LLM
},
"ttsStats": {
  "totalGenerationTime": 5138,    // ‚Üê Temps total de g√©n√©ration TTS (ms)
  "totalPrice": 0.0245,
  "instances": [{
    "generatedSeconds": 17.18,    // ‚Üê Dur√©e audio g√©n√©r√©e
    "generatedChars": 377          // ‚Üê Nb caract√®res g√©n√©r√©s
  }]
}
```

**B. Co√ªts t√©l√©phonie** :
```json
"callInfos": {
  "callCost": 0.0404,             // Co√ªt Twilio
  "callPriceUnit": "USD"
}
"diplerCommission": 0.01733,      // Commission Dipler
"sessionTotalPriceIncludingTwilioNotBilledByDipler": 0.10378
```

**‚úÖ UTILE pour :**
- **Analyse de rentabilit√© fine** : Co√ªt par composant
- **Optimisation des co√ªts** : Identifier quel composant co√ªte le plus
- **Pr√©diction de co√ªts** : Estimer le co√ªt d'un appel en fonction des tokens
- **Dashboard financier avanc√©** : Breakdown par techno (STT vs TTS vs LLM vs Telecom)

---

## 5. üéôÔ∏è Qualit√© Audio & Performance TTS

### Donn√©es TTS par message :
```json
"ttsStats": {
  "price": 0.01033,
  "nbChars": 159,                 // Nombre de caract√®res
  "durationSeconds": 6.502,       // Dur√©e audio g√©n√©r√©e
  "voiceKey": "cartesiaTts:..."   // Voix utilis√©e
}
```

**‚úÖ UTILE pour :**
- **Vitesse de parole** : nbChars / durationSeconds = chars/seconde
- **Comparaison de voix** : Quelle voix g√©n√®re le plus rapidement ?
- **Optimisation de verbosit√©** : D√©tecter les messages trop longs
- **Coh√©rence** : Dur√©e moyenne d'un message par agent

**Calcul possible** :
- Vitesse de parole moyenne : ~24 chars/seconde (159 chars / 6.5s)
- Messages trop longs : > 30 secondes
- Messages trop courts : < 2 secondes

---

## 6. üìù Tokens & Contexte LLM

### Statistiques LLM d√©taill√©es :
```json
"systemPromptStats": {
  "charCount": 21999,
  "tokenCount": 5711              // ‚Üê Taille du system prompt
},
"llmStats": {
  "textInputTokens": 65870,       // Total tokens input (toute la conversation)
  "textOutputTokens": 227,        // Total tokens output
  "generationsCount": 5           // Nombre d'appels LLM
}
```

**Par message** :
```json
"llmStats": {
  "textInputTokens": 13114,       // Tokens input pour CE message
  "textOutputTokens": 48,         // Tokens output pour CE message
  "model": "gemini-2.5-flash"
}
```

**‚úÖ TR√àS UTILE pour :**
- **Optimisation du prompt** : System prompt trop long ? (5711 tokens = co√ªteux)
- **Croissance du contexte** : Tracking de l'augmentation des tokens au fil de la conversation
- **D√©tection de prompts inefficaces** : textInputTokens √©lev√©s avec peu d'output
- **Co√ªt par g√©n√©ration** : Prix moyen d'un appel LLM
- **Efficacit√© du mod√®le** : Output tokens / Input tokens ratio

**Analyse possible** :
- Graphique : Evolution des tokens input au fil des turns
- KPI : Token efficiency = Output / Input
- Alerte : Conversations qui d√©passent le context window

---

## 7. üó£Ô∏è Analyse conversationnelle avanc√©e

### A. Messages et Turns
```json
"messageCount": 8,                // Nombre de messages √©chang√©s
"conversation.messages": [...]    // Tous les messages avec timestamps
```

**‚úÖ UTILE pour :**
- **Longueur de conversation** : Nombre moyen de tours de parole
- **Distribution** : Combien de conversations ont X tours ?
- **D√©tection d'abandons** : Conversations trop courtes (< 3 messages)
- **Engagement** : Plus de tours = meilleur engagement ?

### B. Transcript complet
```json
"transcript": "User : ... Model : ... User : ..."
```

**‚úÖ UTILE pour :**
- **Analyse s√©mantique** : Extraction de mots-cl√©s, entit√©s
- **D√©tection de probl√®mes r√©currents** : Quelles questions reviennent ?
- **Formation du mod√®le** : Dataset pour fine-tuning
- **Analyse de compliance** : V√©rifier que l'agent suit le script

### C. Tool Calls
```json
"functionCall": {
  "name": "hangUp",
  "args": {"isVoiceMail": true}
}
```

**‚úÖ UTILE pour :**
- **Usage des fonctions** : Quels tools sont les plus appel√©s ?
- **Taux de succ√®s** : sendConfirmation appel√© = RDV pris ?
- **Analyse de flow** : Combien d'appels avant hangUp ?
- **D√©tection d'erreurs** : Tool calls √©chou√©s ?

---

## 8. üì° Configuration & Stack technique

### Stack utilis√© :
```json
"stack": {
  "stt": "sstt",
  "llm": "gemini-2.5-flash",
  "tts": [{
    "ttsProvider": "cartesiaTts",
    "voiceId": "39881201-9d47-45f6-b8e1-f7a1ea55da1f",
    "languageRule": "default"
  }]
}
```

**‚úÖ UTILE pour :**
- **A/B Testing** : Comparer gemini-2.5-flash vs autres mod√®les
- **Performance par provider** : SStt vs Azure vs Google STT
- **Optimisation voix** : Quelle voix performe le mieux ?
- **Tra√ßabilit√©** : Savoir exactement quelle config a √©t√© utilis√©e

---

## 9. üé§ Enregistrements Audio

### URLs sign√©es disponibles :
```json
"recordingSignedUrl": "...",           // Enregistrement complet
"userMicRecordingSignedUrl": "...",    // Audio utilisateur seul
"vadAudioRecordingSignedUrl": "..."    // Audio VAD
```

**‚úÖ UTILE pour :**
- **Contr√¥le qualit√©** : √âcouter les appels probl√©matiques
- **Formation √©quipe** : Partager exemples de bons/mauvais appels
- **Analyse audio avanc√©e** : D√©tection d'√©motions par analyse vocale
- **Compliance** : Archivage l√©gal des enregistrements

---

## 10. üìã Variables de session & Contexte CRM

### Variables inject√©es :
```json
"sessionVariables": {
  "voipiaCallId": "...",
  "personCRMId": "228",
  "mail": "brice@voipia.fr",
  "dealId": "279",
  "deploymentId": "...",
  "telephone": "+33648057431",
  "prenom": "Brice",
  "nom": "Testgacha",
  "direction": "outbound"
}
```

**‚úÖ UTILE pour :**
- **Enrichissement CRM** : Lier appel √† Pipedrive/HubSpot
- **Segmentation** : Analyser par deal, par personne
- **Attribution** : Quel deployment a g√©n√©r√© l'appel ?
- **Direction** : Comparer inbound vs outbound

---

## üìä Recommandations pour enrichir agent_calls

### Colonnes √† ajouter (par priorit√©) :

#### üî¥ Haute priorit√©

1. **Sentiment & Qualit√©** :
   - `sentiment` (ENUM: 'positive', 'negative', 'neutral')
   - `sentiment_explanation` (TEXT)
   - `conversation_summary` (TEXT)

2. **Latences d√©taill√©es** :
   - `llm_latency_avg` (FLOAT) - ms
   - `llm_latency_min` (FLOAT) - ms
   - `llm_latency_max` (FLOAT) - ms
   - `tts_latency_avg` (FLOAT) - ms
   - `first_response_latency` (FLOAT) - Temps avant 1√®re r√©ponse

3. **Tokens & Contexte** :
   - `llm_input_tokens` (INTEGER)
   - `llm_output_tokens` (INTEGER)
   - `llm_generations_count` (INTEGER) - Nb d'appels LLM
   - `system_prompt_tokens` (INTEGER)

#### üü° Priorit√© moyenne

4. **Performance conversationnelle** :
   - `message_count` (INTEGER) - Nombre de tours de parole
   - `user_speech_duration` (FLOAT) - Dur√©e totale de parole utilisateur
   - `agent_speech_duration` (FLOAT) - Dur√©e totale de parole agent
   - `silence_duration` (FLOAT) - Dur√©e totale de silences

5. **TTS/STT d√©tails** :
   - `tts_chars_generated` (INTEGER)
   - `tts_audio_duration` (FLOAT) - secondes
   - `stt_duration` (FLOAT) - secondes d'audio transcrit
   - `speech_rate` (FLOAT) - chars/seconde (vitesse de parole)

#### üü¢ Priorit√© basse (nice to have)

6. **Co√ªts d√©taill√©s** :
   - `dipler_commission` (DECIMAL)
   - `twilio_cost` (DECIMAL)
   - `total_cost_with_telco` (DECIMAL)

7. **Technique** :
   - `llm_model` (VARCHAR) - ex: "gemini-2.5-flash"
   - `tts_provider` (VARCHAR) - ex: "cartesiaTts"
   - `stt_provider` (VARCHAR) - ex: "sstt"
   - `voice_id` (VARCHAR)

8. **Audio & Enregistrements** :
   - `recording_url` (TEXT) - URL S3 de l'enregistrement
   - `has_recording` (BOOLEAN)

---

## üéØ Cas d'usage avanc√©s

### 1. Dashboard Qualit√©
- **Taux de satisfaction** : % sentiment positive
- **Appels probl√©matiques** : Liste des sentiment negative avec explanations
- **Top 5 probl√®mes r√©currents** : Analyse des sentiment_explanation

### 2. Dashboard Performance
- **Latence moyenne par agent** : Comparer Louis vs Arthur vs Alexandra
- **√âvolution de la latence** : Graphique temporel
- **Peak hours** : Quelles heures ont les pires latences ?

### 3. Dashboard Efficacit√© conversationnelle
- **Dur√©e moyenne par outcome** : appointment_scheduled vs voicemail vs not_interested
- **Nombre de tours optimal** : Corr√©lation message_count vs taux de conversion
- **Taux d'interruption** : Combien de fois l'utilisateur coupe l'agent ?

### 4. Dashboard Co√ªts avanc√©
- **Co√ªt par composant** : STT vs TTS vs LLM vs Telecom (pie chart)
- **Co√ªt par minute de conversation** : averagePricePerMinute tracking
- **ROI par appel** : (Revenu - Co√ªt) / Co√ªt
- **Efficacit√© token** : Co√ªt LLM / Nombre de RDV pris

### 5. Analyse pr√©dictive
- **Pr√©dire le sentiment** : ML model avec latences + message_count + duration
- **Pr√©dire le co√ªt** : Estimer co√ªt avant l'appel (bas√© sur historique)
- **D√©tection pr√©coce d'√©chec** : Si latence > X √† turn 2, probabilit√© voicemail √©lev√©e

---

## üöÄ Actions recommand√©es

### Phase 1 : Latences (en cours)
‚úÖ Ajouter `llm_latency_avg`, `llm_latency_max`, `tts_latency_avg`, `first_response_latency`

### Phase 2 : Sentiment & Qualit√©
- Ajouter `sentiment`, `sentiment_explanation`, `conversation_summary`
- Cr√©er dashboard "Appels probl√©matiques"
- Alertes automatiques sur sentiment = 'negative'

### Phase 3 : Tokens & Contexte
- Ajouter `llm_input_tokens`, `llm_output_tokens`, `llm_generations_count`
- Analyse de l'efficacit√© du prompt
- Optimisation du system prompt (r√©duire tokenCount)

### Phase 4 : Performance conversationnelle
- Ajouter `message_count`, `user_speech_duration`, `agent_speech_duration`
- Analyse de la fluidit√© (silences, interruptions)
- KPI : Dur√©e id√©ale de conversation par outcome

### Phase 5 : Co√ªts avanc√©s
- Ajouter breakdown par composant
- Dashboard "Co√ªt par technologie"
- Optimisation bas√©e sur co√ªt/performance ratio

---

## üí° Conclusion

Vous avez acc√®s √† **beaucoup plus de donn√©es que vous n'utilisez actuellement** !

**Top 3 des donn√©es les plus impactantes √† ajouter** :
1. **Sentiment Analysis** ‚Üí Comprendre la satisfaction client
2. **Message Count & Speech Durations** ‚Üí Analyser l'engagement conversationnel
3. **LLM Tokens d√©taill√©s** ‚Üí Optimiser les co√ªts et le prompt

Ces donn√©es vous permettront de passer d'un dashboard "op√©rationnel" (combien d'appels ?) √† un dashboard "strat√©gique" (quelle qualit√© d'appels ? comment optimiser ?).

Souhaitez-vous que je vous aide √† impl√©menter l'une de ces phases ?
